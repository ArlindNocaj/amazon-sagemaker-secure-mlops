{
 "cells": [
  {
   "source": [
    "# Using SageMaker pipelines for MLOps workflows\n",
    "\n",
    "This notebook contains end-to-end code to construct and execute a secure MLOps pipeline in your data science environment. It contains all necessary all code in one place. You can use and modify this code for your experiments and tests.\n",
    "  \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import sagemaker.session\n",
    "import json\n",
    "\n",
    "sm = boto3.client(\"sagemaker\")\n",
    "ssm = boto3.client(\"ssm\")\n",
    "\n",
    "def get_environment(project_name):\n",
    "    r = sm.describe_domain(\n",
    "            DomainId=sm.describe_project(\n",
    "                ProjectName=project_name\n",
    "                )[\"CreatedBy\"][\"DomainId\"]\n",
    "        )\n",
    "    del r[\"ResponseMetadata\"]\n",
    "    del r[\"CreationTime\"]\n",
    "    del r[\"LastModifiedTime\"]\n",
    "    r = {**r, **r[\"DefaultUserSettings\"]}\n",
    "    del r[\"DefaultUserSettings\"]\n",
    "\n",
    "    i = {\n",
    "        **r,\n",
    "        **{t[\"Key\"]:t[\"Value\"] \n",
    "            for t in sm.list_tags(ResourceArn=r[\"DomainArn\"])[\"Tags\"] \n",
    "            if t[\"Key\"] in [\"EnvironmentName\", \"EnvironmentType\"]}\n",
    "    }\n",
    "\n",
    "    i[\"DataBucketName\"]=ssm.get_parameter(Name=f\"{i['EnvironmentName']}-{i['EnvironmentType']}-data-bucket-name\")[\"Parameter\"][\"Value\"]\n",
    "    i[\"ModelBucketName\"]=ssm.get_parameter(Name=f\"{i['EnvironmentName']}-{i['EnvironmentType']}-model-bucket-name\")[\"Parameter\"][\"Value\"]\n",
    "    i[\"S3VPCEId\"]=ssm.get_parameter(Name=f\"{i['EnvironmentName']}-{i['EnvironmentType']}-s3-vpce-id\")[\"Parameter\"][\"Value\"]\n",
    "    i[\"S3KmsKeyId\"]=ssm.get_parameter(Name=f\"{i['EnvironmentName']}-{i['EnvironmentType']}-kms-s3-key-arn\")[\"Parameter\"][\"Value\"].split(\"/\")[-1]\n",
    "    i[\"PipelineExecutionRole\"]=ssm.get_parameter(Name=f\"{i['EnvironmentName']}-{i['EnvironmentType']}-sm-pipeline-execution-role-arn\")[\"Parameter\"][\"Value\"]\n",
    "\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to the specific project name to setup the environment\n",
    "project_name = \n",
    "env_data = get_environment(project_name=project_name)\n",
    "print(f\"Environment data:\\n{json.dumps(env_data, indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipelines.abalone.pipeline import get_session\n",
    "\n",
    "sagemaker_session = get_session(boto3.Session().region_name, env_data[\"DataBucketName\"])\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "pipeline_role = env_data[\"PipelineExecutionRole\"]\n",
    "processing_role = env_data[\"ExecutionRole\"]\n",
    "training_role = env_data[\"ExecutionRole\"]\n",
    "data_bucket = sagemaker_session.default_bucket()\n",
    "model_bucket = env_data[\"ModelBucketName\"]\n",
    "\n",
    "print(f\"SageMaker version: {sagemaker.__version__}\")\n",
    "print(f\"Region: {region}\")\n",
    "print(f\"Pipeline execution role: {pipeline_role}\")\n",
    "print(f\"Pipeline data bucket: {data_bucket}\")\n",
    "\n",
    "# Change these to reflect your project/business name or if you want to separate ModelPackageGroup/Pipeline from the rest of your team\n",
    "model_package_group_name = f\"AbaloneModelPackageGroup-Example\"\n",
    "pipeline_name = f\"AbalonePipeline-Example\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "import sagemaker.session\n",
    "\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.model_metrics import (\n",
    "    MetricsSource,\n",
    "    ModelMetrics,\n",
    ")\n",
    "from sagemaker.processing import (\n",
    "    ProcessingInput,\n",
    "    ProcessingOutput,\n",
    "    ScriptProcessor,\n",
    ")\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import (\n",
    "    ConditionStep,\n",
    "    JsonGet,\n",
    ")\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.steps import (\n",
    "    ProcessingStep,\n",
    "    TrainingStep,\n",
    ")\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.network import NetworkConfig\n",
    "\n",
    "BASE_DIR=\"./pipelines/abalone/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # parameters for pipeline execution\n",
    "processing_instance_count = ParameterInteger(name=\"ProcessingInstanceCount\", default_value=1)\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\", default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "training_instance_type = ParameterString(\n",
    "    name=\"TrainingInstanceType\", default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "model_approval_status = ParameterString(\n",
    "    name=\"ModelApprovalStatus\", default_value=\"PendingManualApproval\"\n",
    ")\n",
    "input_data = ParameterString(\n",
    "    name=\"InputDataUrl\",\n",
    "    default_value=f\"s3://{sagemaker_session.default_bucket()}/datasets/abalone-dataset.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_config = NetworkConfig(\n",
    "        enable_network_isolation=False, \n",
    "        security_group_ids=env_data[\"SecurityGroups\"],\n",
    "        subnets=env_data[\"SubnetIds\"],\n",
    "        encrypt_inter_container_traffic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_job_prefix=\"Abalone\"\n",
    "\n",
    "# processing step for feature engineering\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=\"0.23-1\",\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=f\"{base_job_prefix}/sklearn-abalone-preprocess\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=processing_role,\n",
    "    network_config=network_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " step_process = ProcessingStep(\n",
    "        name=\"PreprocessAbaloneData\",\n",
    "        processor=sklearn_processor,\n",
    "        outputs=[\n",
    "            ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n",
    "            ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\"),\n",
    "            ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\"),\n",
    "        ],\n",
    "        code=os.path.join(BASE_DIR, \"preprocess.py\"),\n",
    "        job_arguments=[\"--input-data\", input_data],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training step for generating model artifacts\n",
    "model_path = f\"s3://{sagemaker_session.default_bucket()}/{base_job_prefix}/AbaloneTrain\"\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\",\n",
    "    region=region,\n",
    "    version=\"1.0-1\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=training_instance_type,\n",
    ")\n",
    "xgb_train = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    instance_type=training_instance_type,\n",
    "    instance_count=1,\n",
    "    output_path=model_path,\n",
    "    base_job_name=f\"{base_job_prefix}/abalone-train\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=training_role,\n",
    "    subnets=network_config.subnets,\n",
    "    security_group_ids=network_config.security_group_ids,\n",
    "    encrypt_inter_container_traffic=True,\n",
    "    enable_network_isolation=False\n",
    ")\n",
    "xgb_train.set_hyperparameters(\n",
    "    objective=\"reg:linear\",\n",
    "    num_round=50,\n",
    "    max_depth=5,\n",
    "    eta=0.2,\n",
    "    gamma=4,\n",
    "    min_child_weight=6,\n",
    "    subsample=0.7,\n",
    "    silent=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_train = TrainingStep(\n",
    "    name=\"TrainAbaloneModel\",\n",
    "    estimator=xgb_train,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"train\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"validation\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing step for evaluation\n",
    "script_eval = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=1,\n",
    "    base_job_name=f\"{base_job_prefix}/script-abalone-eval\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=processing_role,\n",
    "    network_config=network_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_report = PropertyFile(\n",
    "        name=\"AbaloneEvaluationReport\",\n",
    "        output_name=\"evaluation\",\n",
    "        path=\"evaluation.json\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_eval = ProcessingStep(\n",
    "        name=\"EvaluateAbaloneModel\",\n",
    "        processor=script_eval,\n",
    "        inputs=[\n",
    "            ProcessingInput(\n",
    "                source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "                destination=\"/opt/ml/processing/model\",\n",
    "            ),\n",
    "            ProcessingInput(\n",
    "                source=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"test\"\n",
    "                ].S3Output.S3Uri,\n",
    "                destination=\"/opt/ml/processing/test\",\n",
    "            ),\n",
    "        ],\n",
    "        outputs=[\n",
    "            ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"),\n",
    "        ],\n",
    "        code=os.path.join(BASE_DIR, \"evaluate.py\"),\n",
    "        property_files=[evaluation_report],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register model step that will be conditionally executed\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=\"{}/evaluation.json\".format(\n",
    "            step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "        ),\n",
    "        content_type=\"application/json\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vpc_config = {\n",
    "    \"Subnets\":network_config.subnets,\n",
    "    \"SecurityGroupIds\":network_config.security_group_ids\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "There is a bug in RegisterModel implementation\n",
    "The RegisterModel step is implemented in the SDK as two steps, a _RepackModelStep and a _RegisterModelStep. \n",
    "The _RepackModelStep runs a SKLearn training step in order to repack the model.tar.gz to include any custom inference code in the archive. \n",
    "The _RegisterModelStep then registers the repacked model.\n",
    "\n",
    "The problem is that the _RepackModelStep does not propagate VPC configuration from the Estimator object:\n",
    "https://github.com/aws/sagemaker-python-sdk/blob/cdb633b3ab02398c3b77f5ecd2c03cdf41049c78/src/sagemaker/workflow/_utils.py#L88\n",
    "\n",
    "This cause the AccessDenied exception because repacker cannot access S3 bucket (all access which is not via VPC endpoint is bloked by the bucket policy)\n",
    "\n",
    "The issue is opened against SageMaker module: https://github.com/aws/sagemaker-python-sdk/issues/2302\n",
    "\"\"\"\n",
    "\n",
    "step_register = RegisterModel(\n",
    "    name=\"RegisterAbaloneModel\",\n",
    "    estimator=xgb_train,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.large\"],\n",
    "    transform_instances=[\"ml.m5.large\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    "    model_metrics=model_metrics,\n",
    "    vpc_config_override=vpc_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train.get_vpc_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition step for evaluating model quality and branching execution\n",
    "cond_lte = ConditionLessThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step=step_eval,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"regression_metrics.mse.value\"\n",
    "    ),\n",
    "    right=6.0,\n",
    ")\n",
    "step_cond = ConditionStep(\n",
    "    name=\"CheckMSEAbaloneEvaluation\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_register],\n",
    "    else_steps=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline instance\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_type,\n",
    "        processing_instance_count,\n",
    "        training_instance_type,\n",
    "        model_approval_status,\n",
    "        input_data,\n",
    "    ],\n",
    "    steps=[step_process, step_train, step_eval, step_cond],\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=pipeline_role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = json.loads(pipeline.definition())\n",
    "print(json.dumps(parsed, indent=2, sort_keys=True))"
   ]
  },
  {
   "source": [
    "The following line starts the pipeline execution. In this specific example it runs for about 13 minutes."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}