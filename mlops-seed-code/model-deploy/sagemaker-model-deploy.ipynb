{
 "cells": [
  {
   "source": [
    "# SageMaker model deployment as CI/CD pipeline\n",
    "This notebook demonstrates how to use SageMaker Project template for CI/CD model deployment."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Load packages and get environment configuration "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "import json\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker.session\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "sm = boto3.client(\"sagemaker\")\n",
    "ssm = boto3.client(\"ssm\")\n",
    "\n",
    "def get_environment(project_name, ssm_params):\n",
    "    r = sm.describe_domain(\n",
    "            DomainId=sm.describe_project(\n",
    "                ProjectName=project_name\n",
    "                )[\"CreatedBy\"][\"DomainId\"]\n",
    "        )\n",
    "    del r[\"ResponseMetadata\"]\n",
    "    del r[\"CreationTime\"]\n",
    "    del r[\"LastModifiedTime\"]\n",
    "    r = {**r, **r[\"DefaultUserSettings\"]}\n",
    "    del r[\"DefaultUserSettings\"]\n",
    "\n",
    "    i = {\n",
    "        **r,\n",
    "        **{t[\"Key\"]:t[\"Value\"] \n",
    "            for t in sm.list_tags(ResourceArn=r[\"DomainArn\"])[\"Tags\"] \n",
    "            if t[\"Key\"] in [\"EnvironmentName\", \"EnvironmentType\"]}\n",
    "    }\n",
    "\n",
    "    for p in ssm_params:\n",
    "        try:\n",
    "            i[p[\"VariableName\"]] = ssm.get_parameter(Name=f\"{i['EnvironmentName']}-{i['EnvironmentType']}-{p['ParameterName']}\")[\"Parameter\"][\"Value\"]\n",
    "        except:\n",
    "            i[p[\"VariableName\"]] = \"\"\n",
    "\n",
    "    return i\n",
    "\n",
    "def get_session(region, default_bucket):\n",
    "    \"\"\"Gets the sagemaker session based on the region.\n",
    "\n",
    "    Args:\n",
    "        region: the aws region to start the session\n",
    "        default_bucket: the bucket to use for storing the artifacts\n",
    "\n",
    "    Returns:\n",
    "        sagemaker.session.Session instance\n",
    "    \"\"\"\n",
    "\n",
    "    boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "    sagemaker_client = boto_session.client(\"sagemaker\")\n",
    "    runtime_client = boto_session.client(\"sagemaker-runtime\")\n",
    "    return sagemaker.session.Session(\n",
    "        boto_session=boto_session,\n",
    "        sagemaker_client=sagemaker_client,\n",
    "        sagemaker_runtime_client=runtime_client,\n",
    "        default_bucket=default_bucket,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to the specific SageMaker project name\n",
    "project_name = \n",
    "\n",
    "# Dynamically load environmental SSM parameters - provide the list of the variables to load from SSM parameter store\n",
    "ssm_parameters = [\n",
    "    {\"VariableName\":\"DataBucketName\", \"ParameterName\":\"data-bucket-name\"},\n",
    "    {\"VariableName\":\"ModelBucketName\", \"ParameterName\":\"model-bucket-name\"},\n",
    "    {\"VariableName\":\"S3VPCEId\", \"ParameterName\":\"s3-vpce-id\"},\n",
    "    {\"VariableName\":\"S3KmsKeyId\", \"ParameterName\":\"kms-s3-key-arn\"},\n",
    "    {\"VariableName\":\"PipelineExecutionRole\", \"ParameterName\":\"sm-pipeline-execution-role-arn\"},\n",
    "    {\"VariableName\":\"ModelExecutionRole\", \"ParameterName\":\"sm-model-execution-role-name\"},\n",
    "    {\"VariableName\":\"OUStagingId\", \"ParameterName\":\"ou-staging-id\"},\n",
    "    {\"VariableName\":\"OUProdId\", \"ParameterName\":\"ou-prod-id\"},\n",
    "]\n",
    "\n",
    "env_data = get_environment(project_name=project_name)\n",
    "print(f\"Environment data:\\n{json.dumps(env_data, indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SageMaker session\n",
    "sagemaker_session = get_session(boto3.Session().region_name, env_data[\"DataBucketName\"])\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "pipeline_role = env_data[\"PipelineExecutionRole\"]\n",
    "processing_role = env_data[\"ExecutionRole\"]\n",
    "model_execution_role = env_data[\"ModelExecutionRole\"]\n",
    "training_role = env_data[\"ExecutionRole\"]\n",
    "data_bucket = sagemaker_session.default_bucket()\n",
    "model_bucket = env_data[\"ModelBucketName\"]\n",
    "\n",
    "print(f\"SageMaker version: {sagemaker.__version__}\")\n",
    "print(f\"Region: {region}\")\n",
    "print(f\"Pipeline execution role: {pipeline_role}\")\n",
    "print(f\"Processing role: {processing_role}\")\n",
    "print(f\"Training role: {training_role}\")\n",
    "print(f\"Model execution role: {model_execution_role}\")\n",
    "print(f\"Pipeline data bucket: {data_bucket}\")\n",
    "\n",
    "\n",
    "project_id = sm_client.describe_project(ProjectName=project_name)['ProjectId']\n",
    "# Replace the model_package_group_name with <project_name>, <project_id> with Model Build Train MLOps pipeline\n",
    "model_package_group_name = f\"{project_name}-{project_id}\"\n",
    "print(f\"Model package group name: {model_package_group_name}\")\n",
    "\n",
    "assert(len(project_name) <= 15 ) # the project name should not have more than 15 chars\n",
    "\n",
    "# Prefix for S3 objects\n",
    "prefix=f\"{project_name}-{project_id}\""
   ]
  },
  {
   "source": [
    "## Setup the network config"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'NetworkConfig' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-163899496233>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m network_config = NetworkConfig(\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0menable_network_isolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msecurity_group_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SecurityGroups\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msubnets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SubnetIds\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         encrypt_inter_container_traffic=True)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'NetworkConfig' is not defined"
     ]
    }
   ],
   "source": [
    "network_config = NetworkConfig(\n",
    "        enable_network_isolation=False, \n",
    "        security_group_ids=env_data[\"SecurityGroups\"],\n",
    "        subnets=env_data[\"SubnetIds\"],\n",
    "        encrypt_inter_container_traffic=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "Load the [iris dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html) from `sklearn` module. The iris dataset is a classic and very easy multi-class classification dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "dataset = np.insert(iris.data, 0, iris.target,axis=1)\n",
    "\n",
    "df = pd.DataFrame(data=dataset, columns=['iris_id'] + iris.feature_names)\n",
    "df['species'] = df['iris_id'].map(lambda x: 'setosa' if x == 0 else 'versicolor' if x == 1 else 'virginica')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the dataset to an S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=iris.data\n",
    "y=iris.target\n",
    "\n",
    "# Split the dataset into train and test parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)\n",
    "yX_train = np.column_stack((y_train, X_train))\n",
    "yX_test = np.column_stack((y_test, X_test))\n",
    "np.savetxt(\"iris_train.csv\", yX_train, delimiter=\",\", fmt='%0.3f')\n",
    "np.savetxt(\"iris_test.csv\", yX_test, delimiter=\",\", fmt='%0.3f')\n",
    "\n",
    "# Upload the dataset to an S3 bucket\n",
    "input_train = sagemaker_session.upload_data(path='iris_train.csv', key_prefix=f'{prefix}/datasets/iris/data')\n",
    "input_test = sagemaker_session.upload_data(path='iris_test.csv', key_prefix=f'{prefix}/datasets/iris/data')\n",
    "\n",
    "print(input_train)\n",
    "print(input_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the ML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "\n",
    "training_instance_type = ParameterString(\n",
    "    name=\"TrainingInstanceType\",\n",
    "    default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "training_instance_count = ParameterInteger(\n",
    "    name=\"TrainingInstanceCount\",\n",
    "    default_value=1\n",
    ")\n",
    "input_train_data = ParameterString(\n",
    "    name=\"InputDataTrain\",\n",
    "    default_value=input_train,\n",
    ")\n",
    "input_test_data = ParameterString(\n",
    "    name=\"InputDataTest\",\n",
    "    default_value=input_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimator that will run the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "import time\n",
    "\n",
    "model_path = f\"s3://{model_bucket}/{project_name}-{project_id}/iris-{time.strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\", region=region, version=\"1.0-1\", py_version=\"py3\", \n",
    "    instance_type=training_instance_type,\n",
    ")\n",
    "xgb_train = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    instance_type=training_instance_type,\n",
    "    instance_count=training_instance_count,\n",
    "    output_path=model_path,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    ")\n",
    "xgb_train.set_hyperparameters(\n",
    "    eta=0.1,\n",
    "    max_depth=10,\n",
    "    gamma=4,\n",
    "    num_class=len(np.unique(y)),\n",
    "    alpha=10,\n",
    "    min_child_weight=6,\n",
    "    silent=0,\n",
    "    objective='multi:softmax',\n",
    "    num_round=30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name=\"IrisTrain\",\n",
    "    estimator=xgb_train,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(s3_data=input_train_data, content_type=\"text/csv\"),\n",
    "        \"validation\": TrainingInput(s3_data=input_test_data, content_type=\"text/csv\"\n",
    "        )\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model register step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "# NOTE: model_approval_status is not available as arg in service dsl currently\n",
    "step_register = RegisterModel(\n",
    "    name=\"IrisRegisterModel\",\n",
    "    estimator=xgb_train,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.xlarge\"],\n",
    "    transform_instances=[\"ml.m5.xlarge\"],\n",
    "    model_package_group_name=model_package_group_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.exceptions import ClientError, ValidationError\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "# NOTE:\n",
    "# condition steps have issues in service so we go straight to step_register\n",
    "pipeline_name = \"IrisTrainRegister-%s\" % ts\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        training_instance_type,\n",
    "        training_instance_count,        \n",
    "        input_train_data,\n",
    "        input_test_data\n",
    "    ],\n",
    "    steps=[step_train, step_register],\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "try:\n",
    "    response = pipeline.create(role_arn=role)\n",
    "except ClientError as e:\n",
    "    error = e.response[\"Error\"]\n",
    "    if error[\"Code\"] == \"ValidationError\" and \"Pipeline names must be unique within\" in error[\"Message\"]:\n",
    "        print(error[\"Message\"])\n",
    "        response = pipeline.describe()\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "pipeline_arn = response[\"PipelineArn\"]\n",
    "sm_client.add_tags(\n",
    "    ResourceArn=pipeline_arn,\n",
    "    Tags=[\n",
    "        {'Key': 'sagemaker:project-name', 'Value': project_name },\n",
    "        {'Key': 'sagemaker:project-id', 'Value': project_id }\n",
    "    ]\n",
    ")\n",
    "print(pipeline_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_response = pipeline.start(parameters={\n",
    "    \"TrainingInstanceCount\": \"1\"\n",
    "})\n",
    "\n",
    "pipeline_execution_arn = start_response.arn\n",
    "print(pipeline_execution_arn)\n",
    "\n",
    "while True:\n",
    "    resp = sm_client.describe_pipeline_execution(PipelineExecutionArn=pipeline_execution_arn)\n",
    "    if resp['PipelineExecutionStatus'] == 'Executing':\n",
    "        print('Running...')\n",
    "    else:\n",
    "        print(resp['PipelineExecutionStatus'], pipeline_execution_arn)\n",
    "        break\n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, approve the model to kick-off the deployment process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all packages and select the latest one\n",
    "packages = sm_client.list_model_packages(ModelPackageGroupName=model_package_group_name)['ModelPackageSummaryList']\n",
    "packages = sorted(packages, key=lambda x: x['CreationTime'], reverse=True)\n",
    "\n",
    "latest_model_package_arn = packages[0]['ModelPackageArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_update_response = sm_client.update_model_package(\n",
    "    ModelPackageArn=latest_model_package_arn,\n",
    "    ModelApprovalStatus=\"Approved\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "name": "python391jvsc74a57bd0ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc",
   "display_name": "Python 3.9.1 64-bit ('python@3.9')"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "metadata": {
   "interpreter": {
    "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}